{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-24T19:17:53.251629Z",
     "start_time": "2025-11-24T19:17:52.830968200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MATRIZ TÉRMINO-DOCUMENTO ===\n",
      "(Valores: tf/T - frecuencia normalizada)\n",
      "\n",
      "==================================================\n",
      "             doc1   doc2   doc3\n",
      "machine     0.143  0.000  0.000\n",
      "learning    0.286  0.333  0.000\n",
      "data        0.286  0.000  0.000\n",
      "science     0.143  0.000  0.000\n",
      "algorithm   0.143  0.000  0.000\n",
      "deep        0.000  0.333  0.000\n",
      "neural      0.000  0.167  0.000\n",
      "network     0.000  0.167  0.000\n",
      "natural     0.000  0.000  0.143\n",
      "language    0.000  0.000  0.286\n",
      "processing  0.000  0.000  0.143\n",
      "text        0.000  0.000  0.286\n",
      "mining      0.000  0.000  0.143\n",
      "\n",
      "==================================================\n",
      "\n",
      "=== TÉRMINOS MÁS RELEVANTES POR DOCUMENTO ===\n",
      "\n",
      "Documento 1 ('doc1'):\n",
      "  - learning: 0.286\n",
      "  - data: 0.286\n",
      "  - machine: 0.143\n",
      "\n",
      "Documento 2 ('doc2'):\n",
      "  - learning: 0.333\n",
      "  - deep: 0.333\n",
      "  - neural: 0.167\n",
      "\n",
      "Documento 3 ('doc3'):\n",
      "  - language: 0.286\n",
      "  - text: 0.286\n",
      "  - natural: 0.143\n",
      "\n",
      "=== ANÁLISIS ADICIONAL ===\n",
      "Total de términos únicos en la colección: 13\n",
      "Términos únicos: ['algorithm', 'data', 'deep', 'language', 'learning', 'machine', 'mining', 'natural', 'network', 'neural', 'processing', 'science', 'text']\n",
      "\n",
      "Cálculo detallado para 'doc1':\n",
      "Total de términos: 7\n",
      "Frecuencias brutas:\n",
      "  machine: 1/7 = 0.143\n",
      "  learning: 2/7 = 0.286\n",
      "  data: 2/7 = 0.286\n",
      "  science: 1/7 = 0.143\n",
      "  algorithm: 1/7 = 0.143\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "class ModeloEspacioVectorial:\n",
    "    def __init__(self):\n",
    "        self.documentos = {}  # {nombre_doc: tokens}\n",
    "        self.matriz_tf = None\n",
    "        self.terminos = set()\n",
    "        self.nombres_docs = []\n",
    "\n",
    "    def agregar_documento(self, nombre, tokens):\n",
    "        \"\"\"Añade un documento a la colección\"\"\"\n",
    "        self.documentos[nombre] = tokens\n",
    "        self.terminos.update(tokens)\n",
    "        self.nombres_docs.append(nombre)\n",
    "\n",
    "    def calcular_tf(self, tokens):\n",
    "        \"\"\"Calcula frecuencias normalizadas para un documento\"\"\"\n",
    "        total_terminos = len(tokens)\n",
    "        frecuencias = Counter(tokens)\n",
    "\n",
    "        # Normalizar por total de términos: tf / T\n",
    "        tf_normalizado = {}\n",
    "        for termino, freq in frecuencias.items():\n",
    "            tf_normalizado[termino] = freq / total_terminos\n",
    "\n",
    "        return tf_normalizado\n",
    "\n",
    "    def construir_matriz(self):\n",
    "        \"\"\"Construye la matriz término-documento\"\"\"\n",
    "        if not self.documentos:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        # Inicializar matriz con ceros\n",
    "        matriz_data = {}\n",
    "\n",
    "        for doc_name, tokens in self.documentos.items():\n",
    "            tf_doc = self.calcular_tf(tokens)\n",
    "            matriz_data[doc_name] = tf_doc\n",
    "\n",
    "        # Crear DataFrame\n",
    "        self.matriz_tf = pd.DataFrame(matriz_data).fillna(0)\n",
    "\n",
    "        # Reordenar columnas según el orden de inserción\n",
    "        self.matriz_tf = self.matriz_tf[self.nombres_docs]\n",
    "\n",
    "        return self.matriz_tf\n",
    "\n",
    "    def obtener_terminos_relevantes(self, doc_index, top_n=5):\n",
    "        \"\"\"Devuelve los n términos más importantes para un documento\"\"\"\n",
    "        if self.matriz_tf is None:\n",
    "            self.construir_matriz()\n",
    "\n",
    "        if doc_index >= len(self.nombres_docs):\n",
    "            raise ValueError(\"Índice de documento fuera de rango\")\n",
    "\n",
    "        doc_name = self.nombres_docs[doc_index]\n",
    "\n",
    "        # Obtener términos ordenados por peso descendente\n",
    "        terminos_relevantes = (\n",
    "            self.matriz_tf[doc_name]\n",
    "            .sort_values(ascending=False)\n",
    "            .head(top_n)\n",
    "        )\n",
    "\n",
    "        return terminos_relevantes\n",
    "\n",
    "\n",
    "# Ejemplo de uso y prueba\n",
    "if __name__ == \"__main__\":\n",
    "    # Crear instancia del modelo\n",
    "    modelo = ModeloEspacioVectorial()\n",
    "\n",
    "    # Documentos de prueba\n",
    "    documentos_prueba = {\n",
    "        \"doc1\": [\"machine\", \"learning\", \"data\", \"science\", \"algorithm\", \"data\", \"learning\"],\n",
    "        \"doc2\": [\"deep\", \"learning\", \"neural\", \"network\", \"deep\", \"learning\"],\n",
    "        \"doc3\": [\"natural\", \"language\", \"processing\", \"text\", \"mining\", \"language\", \"text\"]\n",
    "    }\n",
    "\n",
    "    # Agregar documentos al modelo\n",
    "    for nombre, tokens in documentos_prueba.items():\n",
    "        modelo.agregar_documento(nombre, tokens)\n",
    "\n",
    "    # Construir matriz término-documento\n",
    "    matriz = modelo.construir_matriz()\n",
    "\n",
    "    print(\"=== MATRIZ TÉRMINO-DOCUMENTO ===\")\n",
    "    print(\"(Valores: tf/T - frecuencia normalizada)\")\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(matriz.round(3))\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "\n",
    "    # Obtener términos más relevantes por documento\n",
    "    print(\"\\n=== TÉRMINOS MÁS RELEVANTES POR DOCUMENTO ===\")\n",
    "\n",
    "    for i in range(len(documentos_prueba)):\n",
    "        doc_name = modelo.nombres_docs[i]\n",
    "        print(f\"\\nDocumento {i + 1} ('{doc_name}'):\")\n",
    "        terminos_relevantes = modelo.obtener_terminos_relevantes(i, top_n=3)\n",
    "\n",
    "        for termino, peso in terminos_relevantes.items():\n",
    "            print(f\"  - {termino}: {peso:.3f}\")\n",
    "\n",
    "    # Análisis adicional\n",
    "    print(\"\\n=== ANÁLISIS ADICIONAL ===\")\n",
    "    print(f\"Total de términos únicos en la colección: {len(modelo.terminos)}\")\n",
    "    print(f\"Términos únicos: {sorted(list(modelo.terminos))}\")\n",
    "\n",
    "    # Mostrar cálculos detallados para el primer documento\n",
    "    print(f\"\\nCálculo detallado para '{modelo.nombres_docs[0]}':\")\n",
    "    tokens_doc1 = documentos_prueba[\"doc1\"]\n",
    "    total_terminos = len(tokens_doc1)\n",
    "    frecuencias = Counter(tokens_doc1)\n",
    "\n",
    "    print(f\"Total de términos: {total_terminos}\")\n",
    "    print(\"Frecuencias brutas:\")\n",
    "    for termino, freq in frecuencias.items():\n",
    "        tf_normalizado = freq / total_terminos\n",
    "        print(f\"  {termino}: {freq}/{total_terminos} = {tf_normalizado:.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "d8c8f2ad5c67cc0e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
